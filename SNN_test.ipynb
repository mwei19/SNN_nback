{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvkabja4fZNh0loqvQiZW/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mwei19/SNN_nback/blob/main/SNN_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb-WAdOSDQPZ",
        "outputId": "f4cddb12-16fe-4b2d-9365-3ca3c9473490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snntorch\n",
            "  Downloading snntorch-0.5.3-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.5/95.5 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from snntorch) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from snntorch) (1.3.5)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from snntorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from snntorch) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.1.0->snntorch) (4.5.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->snntorch) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->snntorch) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->snntorch) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->snntorch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->snntorch) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->snntorch) (1.15.0)\n",
            "Installing collected packages: snntorch\n",
            "Successfully installed snntorch-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install snntorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/SNN_data')"
      ],
      "metadata": {
        "id": "PsoGXnqjbj76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def rand_net(A, freeze_diag = True):\n",
        "    '''Randomize the elements of a 2D tensor.\n",
        "\n",
        "    Input\n",
        "    -----\n",
        "        \n",
        "    A: tensor\n",
        "        a 2D tensor (e.g., from PyTorch)\n",
        "    \n",
        "    freeze_diag: bool, default=True\n",
        "        indicating if diagonal values should be randomized (=True) \n",
        "        or not (=False).\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "        \n",
        "    X: tensor\n",
        "        a 2D tensor with randomized values from tensor A\n",
        "    \n",
        "    NOTE:\n",
        "        \n",
        "    this option is valid only for non-symmetric tensors, that is,\n",
        "    not every non-zero entry Ai,j corresponds to a non-zero entry Aj,i.\n",
        "    For symmetric tensors, always freeze_diag=True.\n",
        "       \n",
        "    \n",
        "    Examples:\n",
        "        \n",
        "    # if R is symmetric \n",
        "    R_rand = rand_net(R)   \n",
        "        \n",
        "    # if R is non-symmetric    \n",
        "    R_rand = rand_net(R, freeze_diag=False)#Randomize also diag\n",
        "    R_rand = rand_net(R)   \n",
        "    '''  \n",
        "    if check_symmetric(A.data.numpy()):\n",
        "        nodes = A.shape[0]\n",
        "\n",
        "        # Get the idx and values of the lower diagonal - since A is symmetric,\n",
        "        # that is all we need.\n",
        "        X = torch.ones((nodes, nodes)).double() \n",
        "        X = torch.triu(X, diagonal=0)\n",
        "        idx = torch.where(X==0.)\n",
        "        values = A[idx]\n",
        "\n",
        "        # Permute values and assign them to lower triangle + diag positions\n",
        "        values = values[np.random.permutation(len(values))]\n",
        "        X = torch.zeros((nodes, nodes)).double()  \n",
        "        X[idx] = values \n",
        "        X = X + X.transpose(0,1)# transpose to symmetrize  \n",
        "        X = X + torch.diagflat(A.diag())\n",
        "    else: \n",
        "        nodes = A.shape[0]\n",
        "        if freeze_diag:\n",
        "            # Make mask marking the diagonal with 1s - so we work with the \n",
        "            # 0 entries\n",
        "            M = torch.diagflat(torch.ones(nodes,))\n",
        "            idx = torch.where(M==0.)\n",
        "            values = A[idx]\n",
        "            \n",
        "            # Permute the values and assign them to a 2D tensor\n",
        "            values = values[np.random.permutation(len(values))]\n",
        "            X = torch.zeros((nodes, nodes)).double()  \n",
        "            X[idx] = values \n",
        "            # Put the diagonal valeus to the permuted tensor\n",
        "            X = X + torch.diagflat(A.diag())\n",
        "        else:\n",
        "            # Get the idx of each position in the tensor\n",
        "            idx = torch.where(A)\n",
        "            values = A[idx]\n",
        "            \n",
        "            # Permute the values and assign them to a 2D tensor\n",
        "            values = values[np.random.permutation(len(values))]\n",
        "            X = torch.zeros((nodes, nodes)).double()  \n",
        "            X[idx] = values\n",
        "    \n",
        "    return X\n",
        "\n",
        "def check_symmetric(X):\n",
        "    ''' Check is a 2D numpy array is symmetric: if A[i,j] !=0 then A[j,i] !=0   \n",
        "    for every i,j.\n",
        "    Thus, no weights are taken into account to decide if symmetry exists.\n",
        "    \n",
        "    Input:\n",
        "    X: numpy array, 2D\n",
        "    \n",
        "    Output:\n",
        "    Boolean denoting if the numpy array is symmetric    \n",
        "    '''\n",
        "    return np.all(X == X.T)"
      ],
      "metadata": {
        "id": "Nd2TXU5UgPoA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import itertools\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from scipy.stats import spearmanr\n",
        "import torch\n",
        "\n",
        "# import networkmetrics\n",
        "\n",
        "def group_shuffle(X, Y, indexes):\n",
        "    '''Shuffle the rows of X and Y by keeping row with the same index grouped\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    X: ndarray of shape (M,N) \n",
        "    \n",
        "    Y: ndarray of shape (M,K)\n",
        "    \n",
        "    indexes: ndarray of shape (M,) of int that group rows. E.g., rows with \n",
        "        1 in the indexes array are the same contigouus group of observations\n",
        "        to be kept together durign shuffling.\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    X: The shuffled X\n",
        "    \n",
        "    Y: The shuffled Y\n",
        "    \n",
        "    indexes: The shuffled indexes    \n",
        "    '''\n",
        "    unique_indexes = np.unique(indexes)\n",
        "    unique_indexes = unique_indexes[np.random.permutation(len(unique_indexes))]\n",
        "    rearrange_idx = None\n",
        "    for i in range(0, len(unique_indexes)):\n",
        "        idx = np.where(unique_indexes[i] == indexes)[0]\n",
        "        if rearrange_idx is None:\n",
        "            rearrange_idx = idx\n",
        "        else:\n",
        "            rearrange_idx = np.hstack((rearrange_idx, idx))\n",
        "        \n",
        "    X = X[rearrange_idx, :]\n",
        "    Y = Y[rearrange_idx, :] \n",
        "    indexes = indexes[rearrange_idx]\n",
        "    \n",
        "    return X, Y, indexes\n",
        "        \n",
        "def combo_params(params):\n",
        "    '''Create a list with tuples denoting all possible combos of values to run\n",
        "    the model with. Parameters are specified in the dictionary params\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    params: dict, specifying the names and values of the parameters. \n",
        "        Values of the dict are lists of the params (a list of str, int, float)\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    all_combos: list of tuples, each tuple corresponding to one unique\n",
        "        combination of the values of the dict params.\n",
        "        \n",
        "    all_keys: list of str, denoting the names of the parameters and the \n",
        "        position that they occupy in each tuple in all_combos.\n",
        "        For instance, parameter values in all_combos[0][0] correspond to param\n",
        "        with name all_keys[0]\n",
        "    '''\n",
        "    all_values = []\n",
        "    all_keys = []\n",
        "    # assemble the values of the dictionaries in a list \n",
        "    for value in params.values():\n",
        "        all_values.append(value)\n",
        "        \n",
        "    # assemble the keys of the dictionaries in a list \n",
        "    for keys in params.keys():                                                 \n",
        "        all_keys.append(keys)\n",
        "                 \n",
        "    all_combos = list(itertools.product(*all_values))\n",
        "    \n",
        "    return all_combos, all_keys\n",
        "           \n",
        "def map_weights_to_template(w_template = None, w_to_map = None):\n",
        "    '''Reorder the values of w_to_map in such a way that the valeus obey the \n",
        "    rank ordering of the values in w_template.\n",
        "    The result is X so that: \n",
        "        rank order of X[i,j] == rank order of w_template[i,j] where \n",
        "        i,j in X[i,j] belongs to all non_zeros values in w_to_map \n",
        "     \n",
        "    Input\n",
        "    -----\n",
        "    w_template: torch.Tensor tensor of size (N,M) specifying the rank order \n",
        "        of values to be used as reference for reordering the valeus of the \n",
        "        w_to_map tensor.\n",
        "    \n",
        "    w_to_map: torch.Tensor tensor of size (N,M) containing the values to be \n",
        "        reordered so that their rank ordering matches the rank ordering of the\n",
        "        corresponding values of w_template.\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    X: torch.Tensor tensor of size (N,M) with the reordered values of w_to_map\n",
        "        such that:\n",
        "            rank order of X[i,j] == rank order of w_template[i,j] where \n",
        "            i,j in X[i,j] belongs to all non_zeros values in w_to_map \n",
        "    '''\n",
        "    X = torch.zeros(w_template.shape)\n",
        "    idx = torch.where(w_template!=0)\n",
        "    w_template_values = w_template[idx]\n",
        "    w_to_map_values = w_to_map[idx]\n",
        "    \n",
        "    (sorted_w_template, \n",
        "    sorted_index_w_template) = torch.sort(w_template_values, \n",
        "                                          dim = 0, \n",
        "                                          descending=True)\n",
        "    \n",
        "    (sorted_w_to_map, \n",
        "     sorted_index_w_to_map) = torch.sort(w_to_map_values, \n",
        "                                         dim = 0, \n",
        "                                         descending=True)\n",
        "        \n",
        "    X[idx[0][sorted_index_w_template], \n",
        "      idx[1][sorted_index_w_template]] = sorted_w_to_map                                               \n",
        "                                                   \n",
        "    return X   \n",
        "\n",
        "# Auxiliary function to get the desired parameters from the model\n",
        "# model: the model from which we should fetch parameters \n",
        "# params_to_get: a list of str specifying the names of the params to be fetched     \n",
        "def get_model_params(model, params_to_get = None):\n",
        "    '''Extracts the parameters, names, and 'requires gradient' status from a \n",
        "    model.\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    model: class instance based on the base class torch.nn.Module\n",
        "    \n",
        "    params_to_get: list of str, default=None, specifying the names of the \n",
        "        parameters to be extracted.\n",
        "        If None, then all parameters and names of parameters from the model \n",
        "        will be extracted\n",
        "    \n",
        "    Output\n",
        "    ------     \n",
        "    params_name:, list, contaning one str for each extracted parameter\n",
        "    \n",
        "    params_values: list, containg one tensor corresponding to each \n",
        "        parameter. NOTE: The tensor is detached from the computation graph \n",
        "    req_grad_orig: list, containing one Boolean variable for each parameter\n",
        "        denoting the requires_grad status of the original tensor/parameter \n",
        "        of the model     \n",
        "    '''    \n",
        "    params_names = []\n",
        "    params_values = [] \n",
        "    req_grad_orig = []\n",
        "    for name, param in zip(model.named_parameters(), model.parameters()):             \n",
        "        if params_to_get is not None:\n",
        "            if name[0] in params_to_get: \n",
        "                params_names.append(name[0])\n",
        "                params_values.append(param.detach().clone())\n",
        "                req_grad_orig.append(param.requires_grad)\n",
        "        else:\n",
        "            params_names.append(name[0])\n",
        "            params_values.append(param.detach().clone())\n",
        "            req_grad_orig.append(param.requires_grad)\n",
        "                       \n",
        "    return params_values, params_names, req_grad_orig\n",
        "\n",
        "# Freeze (update=False) or unfreeze (update=True) model params\n",
        "def freeze_params(model, \n",
        "                  params_to_freeze = None,\n",
        "                  update = True):  \n",
        "    '''Freeze or unfreeze the parametrs of a model\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    model:  class instance based on the base class torch.nn.Module\n",
        "    \n",
        "    params_to_freeze: list of str specifying the names of the params to be \n",
        "        frozen or unfrozen\n",
        "        \n",
        "    update: bool, default True, specifying the freeze (update=False) or \n",
        "        unfreeze (update=True) of model params \n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    model: class instance based on the base class torch.nn.Module with changed\n",
        "        requires_grad param for the anmes params in params_to_freeze\n",
        "        (freeze = requires_grad is False unfreeze = requires_grad is True)   \n",
        "    '''\n",
        "    for name, param in zip(model.named_parameters(), model.parameters()):             \n",
        "        if params_to_freeze is not None:\n",
        "            if name[0] in params_to_freeze: \n",
        "                param.requires_grad = update \n",
        "        else:\n",
        "            param.requires_grad = update \n",
        "    \n",
        "    return model\n",
        "\n",
        "def calc_accuracy(output = None, labels = None):\n",
        "    '''Classification accuracy calculation as acc = (TP + TN) / nr total pred\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    output: torch.Tensor tensor of size (N,M) where N are the observations and \n",
        "        M the classes. Values must be such that highest values denote the \n",
        "        most probable class prediction.\n",
        "    \n",
        "    labels: torch.Tensor tensor of size (N,) of int denoting for each of the N\n",
        "        observations the class that it belongs to, thus int must be in the \n",
        "        range 0 to M-1\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    acc: float, accuracy of the predictions    \n",
        "    '''\n",
        "    _ , predicted = torch.max(output.data, 1)\n",
        "    total = labels.size(0)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    acc = 100*(correct/total)\n",
        "\n",
        "    return acc\n",
        "\n",
        "def save_model_state(model, \n",
        "                     epoch = None, \n",
        "                     iteration = None,\n",
        "                     folder_name = None):\n",
        "       '''Save the model's state dict\n",
        "       \n",
        "       Input\n",
        "       -----\n",
        "       model: class instance based on the base class torch.nn.Module\n",
        "       \n",
        "       epoch: positive int, denoting the training epoch in which the model to \n",
        "           be saved is in\n",
        "       \n",
        "       iteration: positive int, denoting the iteration in which the model to be \n",
        "           saved is in. Iteration is 1 complete training cycle of the model\n",
        "           across N epochs.\n",
        "           NOTE: This should not be confused with the number of times a batch \n",
        "           of data passed through the algorithm (also called iteration).\n",
        "       \n",
        "       folder_name: object of class pathlib.PosixPath\n",
        "           The folder in which the model state dict will be stored \n",
        "       '''\n",
        "       file_name = 'model_state_dict' + '_epoch_' + str(epoch) + '_iter_' + str(iteration) + '.pth'\n",
        "       file_to_save = folder_name / file_name\n",
        "       torch.save(model.state_dict(), file_to_save)   \n",
        "       \n",
        "# Load pretrained model\n",
        "def load_pretrained(model,\n",
        "                    pretrained_folder = None, \n",
        "                    epoch = 0,\n",
        "                    it = 0,\n",
        "                    combo_nr = 0):\n",
        "    '''Load the model's state dict\n",
        "       \n",
        "    Input\n",
        "    -----\n",
        "    model: class instance based on the base class torch.nn.Module\n",
        "    \n",
        "    pretrained_folder: object of class pathlib.PosixPath\n",
        "        The folder in which the model state dict will be stored \n",
        "           \n",
        "    epoch: positive int, denoting the training epoch in which the model to \n",
        "        be saved is in\n",
        "       \n",
        "    it: positive int, denoting the iteration in which the model to be \n",
        "        saved is in. Iteration is 1 complete training cycle of the model\n",
        "        across N epochs.\n",
        "        NOTE: This should not be confused with the number of times a batch \n",
        "        of data passed through the algorithm (also called iteration).\n",
        "    \n",
        "    combo_nr: positive int, denoting the nr of the parameter combination\n",
        "        that corresponds to the trained stored model. \n",
        "        The int value can be arbitrary with the only constrained that it is \n",
        "        unique, that is, each int denotes one stored model trained \n",
        "        with a unique combination of parameters.\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    model: class instance based on the base class torch.nn.Module with the \n",
        "        stored state dict      \n",
        "    '''    \n",
        "    file_name = 'model_state_dict_epoch_' + str(epoch) + '_iter_' + str(it) + '.pth'\n",
        "    file_to_open = pretrained_folder / str(combo_nr) / file_name\n",
        "    \n",
        "    model.load_state_dict(torch.load(file_to_open))    \n",
        "    \n",
        "    return model           \n",
        "       \n",
        "# Scale tensor to [0 1] by takin into account the global min and max\n",
        "def scale_tensor(X, global_scaling = True, epsilon = 1e-12):\n",
        "    '''Scale tensor to [0 1] by takin into account the global min and max \n",
        "    (global_scaling=True) or the row-wise min max (global_scaling=False)\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    X : torch.Tensor tensor os size (N,M), the tensor to be rescaled to [0 1]\n",
        "        \n",
        "    global_scaling: bool, default True\n",
        "        Boolean variable specifying if the scaling should be performed by \n",
        "        taking into account the global min and max values (default)\n",
        "        \n",
        "    epsilon: float (default: 1e-12) \n",
        "        A small number to avoid potential divisions with 0  \n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    X_norm: torch.Tensor tensor os size (N,M) which is the rescaled tensor X   \n",
        "    '''\n",
        "    if global_scaling is True:\n",
        "        min_val = torch.min(X)\n",
        "        max_val = torch.max(X)\n",
        "        denom = torch.clamp(max_val-min_val, min = 2*epsilon)\n",
        "        nom = X-min_val\n",
        "        X_norm = torch.div(nom+epsilon, denom)\n",
        "    else:\n",
        "        min_val = torch.min(X, dim=1)[0]\n",
        "        max_val = torch.max(X, dim=1)[0]\n",
        "        denom = torch.clamp(max_val-min_val, min = 2*epsilon)\n",
        "        nom = X.T-min_val\n",
        "        nom = nom.T + epsilon\n",
        "        X_norm = torch.div(nom.T, denom)\n",
        "        X_norm = X_norm.T\n",
        "        \n",
        "    return X_norm   \n",
        "\n",
        "def concatenate_arrays(master_container = None, \n",
        "                       leech = None, \n",
        "                       mode = 'h'):\n",
        "    '''Concatenate ndarrays vertically or horizontally\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    master_container: ndarray, of shape (M,N), default None, that each time \n",
        "        changes from a concatanation with leech. When None, then the leech will\n",
        "        become the master_container\n",
        "        \n",
        "    leech: ndarray, of shape (K,L) that will be concatenated to \n",
        "        master_container. The shape (K,L) must match to the shape (M,N) \n",
        "        dependong on whether the mode of concatenation is horizontal or \n",
        "        vertical. See np.hstack and np.vstack documentation. \n",
        "            \n",
        "    mode: str, default 'h', specifying if the concatenation is horizontal ('h') \n",
        "        or vertical ('v').\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    master_container: ndarray of shape (M,N+L) if mode='h' or (M+K,N) if \n",
        "        mode='v'.\n",
        "        \n",
        "    '''\n",
        "    if master_container is not None:\n",
        "        if mode == 'h':\n",
        "            master_container = np.hstack((master_container, leech))\n",
        "        if mode == 'v':\n",
        "            master_container = np.vstack((master_container, leech))\n",
        "    else:\n",
        "        master_container = leech  \n",
        "        \n",
        "    return master_container  \n",
        "\n",
        "def calculate_metrics(model,\n",
        "                      file_to_model = None, \n",
        "                      metrics = [],\n",
        "                      params_to_get = None):\n",
        "    '''Compute network metrics on a specified layer of a given PyTorch model that \n",
        "    is stored.\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    model: a class instance based on the base class torch.nn.Module. The \n",
        "        model must contain at least a recurrent layer (to be named explicitly\n",
        "        in params_to_get)\n",
        "        \n",
        "    file_to_model: object of class pathlib.PosixPath specifying the full path\n",
        "        to the stored model\n",
        "    metrics: list of str, default [], with the metrics to be computed on each \n",
        "        reccurent layer.\n",
        "        Currently to options:\n",
        "            'hi': homophily index\n",
        "            'sil': silhouette specifyign the clusterness of the recurrent\n",
        "                mlayer as specified by kmeans\n",
        "    params_to_get: str specifying the name of the reccurent layer to use\n",
        "        for computing the metrics.\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    all_metrics: a list containing the metrics    \n",
        "    '''\n",
        "    all_metrics = []# store all the computed metrics in a list\n",
        "    \n",
        "    # Load pretrained model\n",
        "    model.load_state_dict(torch.load(file_to_model))\n",
        "    values, names = get_model_params(model,\n",
        "                                     params_to_get=params_to_get)#select what matrix of the model needs analysis\n",
        "    w = values[0]#this is the matrix that we have to work with\n",
        "    \n",
        "    if 'hi' in metrics:\n",
        "        print('Computing homophily...')\n",
        "        hi = calc_homophily(w.data.numpy())\n",
        "        all_metrics.append(hi)\n",
        "    \n",
        "    if 'sil' in metrics:\n",
        "        print('Computing silhouette...')\n",
        "        scores, labels = get_clusters(\n",
        "                                                      w.data.numpy(), \n",
        "                                                      nr_cluster=[2, 3, 4, 5], \n",
        "                                                      metric='euclidean'\n",
        "                                                      )\n",
        "        all_metrics.append(scores)        \n",
        "    \n",
        "    return all_metrics\n",
        "\n",
        "# Get the min loss\n",
        "def min_loss(losses):\n",
        "    '''Find min value in each row of ndarray losses\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    losses: ndarray of shape (M,N) \n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    all_losses: list containing the min value of each row of losses\n",
        "    '''\n",
        "    all_losses = []\n",
        "    for i in range(losses.shape[0]):\n",
        "        all_losses.append(np.min(losses[i, :]))\n",
        "    \n",
        "    return all_losses \n",
        "   \n",
        "def min_loss_epoch(losses, perc = None):\n",
        "    '''Get the index of min value for each row in losses.\n",
        "    \n",
        "    If a perc is specified, then the index of the min value in each row\n",
        "    satisfies the following:\n",
        "    ((losses-np.min(losses))/(np.max(losses)-np.min(losses)))*100 <= 100-perc\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    losses: ndarray of shape (M,N)\n",
        "    \n",
        "    perc:  int 0 < perc < 100   \n",
        "\n",
        "    Output\n",
        "    ------\n",
        "    all_min_loss_ep: list with an idx for each row denoting where the \n",
        "        min value was observed (taking into account the perc params or not)        \n",
        "    \n",
        "    '''\n",
        "    all_min_loss_ep = [] \n",
        "    if perc is not None: perc = 100-perc      \n",
        "    for i in range(losses.shape[0]):\n",
        "            if perc is None:\n",
        "                value = np.min(losses[i, :])\n",
        "                all_min_loss_ep.append(\n",
        "                                       np.where(value == losses[i, :])[0][0]#get the integer value of the index/epoch\n",
        "                                       )                \n",
        "            else:\n",
        "                val_perc = ((losses[i, :]-np.min(losses[i, :]))/(np.max(losses[i, :])-np.min(losses[i, :])))*100\n",
        "                idx = np.where(val_perc <= perc)[0]\n",
        "                all_min_loss_ep.append(np.min(idx))\n",
        "                \n",
        "    return all_min_loss_ep    \n",
        "\n",
        "def reshape_to_vector(x):\n",
        "    '''Reshape an ndarray x\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    x: ndarray of shape (M,N)\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    x_reshaped: the reshaped x ndarray\n",
        "    \n",
        "    see np.reshape documentation  \n",
        "    '''\n",
        "    x_reshaped =np.reshape(x, \n",
        "                          (x.size), \n",
        "                           'C')\n",
        "\n",
        "    return x_reshaped \n",
        "\n",
        "# Read the results and extract desired quantiities\n",
        "def read_results(results_folder = None, \n",
        "                 results_id = None,\n",
        "                 start = None,\n",
        "                 stop = None):\n",
        "    #Dict to store all raw results\n",
        "    raw_results = {}\n",
        "    \n",
        "    #Dict to store all quantities calculated on raw results\n",
        "    quantities_on_results = {}\n",
        "    \n",
        "    # Get metrics/loss\n",
        "    file_name = 'train_loss_all.npy'\n",
        "    file_to_open = results_folder / str(results_id) / file_name\n",
        "    train_loss_all= np.load(file_to_open)\n",
        "    \n",
        "    # The shape of the results indicate the epochs and iterations\n",
        "    iterations = train_loss_all.shape[0]\n",
        "    total_epochs = train_loss_all.shape[1]\n",
        "    \n",
        "    if stop is None:\n",
        "        stop = total_epochs\n",
        "    \n",
        "    file_name = 'validate_loss_all.npy'\n",
        "    file_to_open = results_folder / str(results_id) / file_name\n",
        "    validate_loss_all = np.load(file_to_open)\n",
        "\n",
        "    current_min_loss = min_loss(validate_loss_all[:, start:stop])\n",
        "    \n",
        "    # get min epoch for loss only for validation\n",
        "    current_min_loss_ep = min_loss_epoch(validate_loss_all[:, start:stop], \n",
        "                                         perc=None)\n",
        "    \n",
        "    # get min epoch for 99% loss only for validation\n",
        "    current_min_loss_ep_perc = min_loss_epoch(validate_loss_all[:, start:stop], \n",
        "                                              perc=99)\n",
        "    \n",
        "    # Check if a file corresponding to metrics exists and is not empty\n",
        "    # (maybe stored empty) and if so, set the boolean value load_metrics to True\n",
        "    load_metrics = False\n",
        "    file_name = 'train_metrics_all.npy'\n",
        "    file_to_open = results_folder / str(results_id) / file_name\n",
        "    metrics_exists = os.path.exists(file_to_open)\n",
        "    \n",
        "    if metrics_exists:\n",
        "        train_metrics_all = np.load(file_to_open)\n",
        "        if train_metrics_all.size > 0:\n",
        "            load_metrics = True\n",
        "    \n",
        "    # Get metrics if load_metrics is True\n",
        "    if load_metrics:\n",
        "        file_name = 'train_metrics_all.npy'\n",
        "        file_to_open = results_folder / str(results_id) / file_name\n",
        "        train_metrics_all = np.load(file_to_open)\n",
        "        \n",
        "        file_name = 'validate_metrics_all.npy'\n",
        "        file_to_open = results_folder / str(results_id) / file_name\n",
        "        validate_metrics_all = np.load(file_to_open)\n",
        "        \n",
        "    #Store results - raw results    \n",
        "    raw_results = {\n",
        "                  'train_loss': train_loss_all[:, start:stop],\n",
        "                  'validate_loss': validate_loss_all[:, start:stop]\n",
        "                  }\n",
        "    \n",
        "    if load_metrics:\n",
        "        raw_results['train_metrics'] = train_metrics_all[:, start:stop]\n",
        "        raw_results['validate_metrics'] = validate_metrics_all[:, start:stop]\n",
        "            \n",
        "    #Store results - quantities calculated on raw results\n",
        "    quantities_on_results = {\n",
        "                            'min_loss': current_min_loss,\n",
        "                            'min_loss_ep': current_min_loss_ep,\n",
        "                            'min_loss_ep_perc': current_min_loss_ep_perc\n",
        "                            }        \n",
        "    \n",
        "    ep = range((stop-start))\n",
        "    \n",
        "    return raw_results, quantities_on_results, ep, iterations \n",
        "\n",
        "def extend_list(list_to_ext = None, ext = None):\n",
        "    '''Extend a list of lists as follows:\n",
        "    Construct a new list of lists ext_list such that the first list of \n",
        "    ext_list is a list of li[n]*ext where li is the ith list in list_to_ext\n",
        "    and n is the nth item of list li. The construction of ext_list proceeds\n",
        "    from n=0..N-1 where N is the length of li.\n",
        "    \n",
        "    Hence all lists li in list_to_ext must have the same length. \n",
        "\n",
        "    Example:\n",
        "    a = [['apple','carrot'],['grape','orange']]\n",
        "    ext_list = extend_list(list_to_ext=a, ext=5)\n",
        "\n",
        "    ext_list=[\n",
        "      ['apple',\n",
        "       'apple',\n",
        "       'apple',\n",
        "       'apple',\n",
        "       'apple',\n",
        "       'grape',\n",
        "       'grape',\n",
        "       'grape',\n",
        "       'grape',\n",
        "       'grape'],\n",
        "      ['carrot',\n",
        "       'carrot',\n",
        "       'carrot',\n",
        "       'carrot',\n",
        "       'carrot',\n",
        "       'orange',\n",
        "       'orange',\n",
        "       'orange',\n",
        "       'orange',\n",
        "       'orange']\n",
        "      ] \n",
        "       \n",
        "    list_to_ext: a list of lists to be expanded\n",
        "    \n",
        "    ext: int, positive, denoting the amount of expansion of each list item\n",
        "        li[n]*ext\n",
        "        \n",
        "    ext_list: the expanded list with the \"expanded\" structure explained above.    \n",
        "    '''\n",
        "    ext_list = []\n",
        "    for i, combo in enumerate(list_to_ext):\n",
        "        for c, item in enumerate(combo):\n",
        "           if i==0:\n",
        "               ext_list.append([item] * ext)\n",
        "           else:\n",
        "               new_item = [item] * ext\n",
        "               ext_list[c] = ext_list[c] + new_item\n",
        "    \n",
        "    return ext_list\n",
        "\n",
        "# Clean string from special characters\n",
        "def clean_str(dirty_string):\n",
        "    '''Clean string from special characters and return a list with the\n",
        "    clean strings. This is a tailored cleaning that corresponds to a \n",
        "    specific input string format.\n",
        "    \n",
        "    Example:\n",
        "    dirty_string= \"(0.1, 'sign', 'of course', 4)\\n\" \n",
        "    clean_strings = clean_str(dirty_string)\n",
        "    clean_strings -> ['0.1', 'sign', 'of course', '4']\n",
        "    '''\n",
        "    clean_strings = re.sub(\"'\", \"\", dirty_string)# remove '   \n",
        "    clean_strings = clean_strings.replace(\"(\",\"\")# remove parentheses\n",
        "    clean_strings = clean_strings.replace(\")\",\"\")\n",
        "    clean_strings = clean_strings.split(',')# split strings\n",
        "    clean_strings = [i.strip() for i in clean_strings]# remove whitespaces\n",
        "    \n",
        "    return clean_strings\n",
        "\n",
        "def get_activation_model(model, \n",
        "                         data_generator = None, \n",
        "                         device = 'cpu'): \n",
        "    '''Obtain the activations of the last hidden layer of an Elman RNN.\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    model: an RNN model, an instance of class nn.Module\n",
        "    data_generator: data generator, torch.utils.data.dataloader.DataLoader,\n",
        "        that feeds the model data to get the  activations \n",
        "    device: str, specifying the device used for performing the forward pass\n",
        "        'cpu' or 'gpu'\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    all_hidden: list of tensors, len N, of shape (B,T,H)\n",
        "        N depends on the batch size (data generator parameter) and the \n",
        "        number of data\n",
        "        B is the batch size, T the time dimension of the data and H are the \n",
        "        nr of hidden units of the reccurent networks.\n",
        "        NOTE that (B,T,H) corresponds to batch_first is True\n",
        "        otheriwise the shape of the tensors is (T,B,H)\n",
        "    '''        \n",
        "    all_hidden = []\n",
        "    # Make sure that the model is not at the training mode\n",
        "    model.train(False)\n",
        "    for X_batch, Y_batch in data_generator:\n",
        "        # Send tensors to the device used\n",
        "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device) \n",
        "        output, hidden = model(X_batch)\n",
        "        # Output is hidden state for eact timepoint - that is what we need\n",
        "        # to keep in a list\n",
        "        all_hidden.append(output.data)\n",
        "                \n",
        "    return all_hidden\n",
        "\n",
        "def compute_coactivation(batch_time_activations):\n",
        "    '''Compute coactivations based on activity in the ndarrray \n",
        "    batch_time_activations  \n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    batch_time_activations: ndarray of shape (B,T,H) with: \n",
        "        B the batch size\n",
        "        T the nr of time steps\n",
        "        H the activations\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    coactivations: ndarray of shape (B,H,H) \n",
        "        this is the coactivation matrix (H,H) for each datapoint in the batch\n",
        "        \n",
        "    '''\n",
        "    all_coact_np = np.zeros((batch_time_activations.shape[0],\n",
        "                             batch_time_activations.shape[2],\n",
        "                             batch_time_activations.shape[2])\n",
        "                            )\n",
        "    for item in range(batch_time_activations.shape[0]): \n",
        "        res = spearmanr(batch_time_activations[item])\n",
        "        current_coact = res[0]\n",
        "        all_coact_np[item,:,:] = current_coact \n",
        "    \n",
        "    return all_coact_np\n",
        "\n",
        "def get_mean_coactivation(all_hidden):\n",
        "    '''Compute mean coactivations based on activity in the list of tensors \n",
        "    all_hidden  \n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    all_hidden: list of len N containing tensors of shape (B,T,H) with: \n",
        "        B the batch size\n",
        "        T the nr of time steps\n",
        "        H the activations\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    mean_coactivations: ndarray of shape (H,H) \n",
        "        this is the mean coactivation matrix (H,H) across N datapoint in the \n",
        "        batch\n",
        "    \n",
        "    '''\n",
        "    all_coactivations = None\n",
        "    for hidden in all_hidden:\n",
        "        coact = compute_coactivation(hidden.data.numpy())   \n",
        "        mean_coact = np.mean(coact, axis=0)\n",
        "        idx = np.where(~np.eye(mean_coact.shape[0], dtype=bool))#get all but the diagonal elements\n",
        "        coactivations = mean_coact[idx]\n",
        "        all_coactivations = concatenate_arrays(master_container=all_coactivations,\n",
        "                                               leech=coactivations,\n",
        "                                               mode='v')\n",
        "    mean_coactivations = np.mean(all_coactivations, axis=0)\n",
        "    \n",
        "    return mean_coactivations "
      ],
      "metadata": {
        "id": "wb4Ahw6ZgKOw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "import torch\n",
        "from torch.utils import data\n",
        "\n",
        "# import auxfun\n",
        "\n",
        "# Dataset class\n",
        "class Dataset(data.Dataset):\n",
        "  '''\n",
        "  Map-style dataset object to be used from the DataLoader\n",
        "  It implements the __get_item()__ and __len()__ methods\n",
        "  See https://pytorch.org/docs/stable/data.html\n",
        "  '''\n",
        "  def __init__(self, trials_in, trials_out, trial_ids):\n",
        "        # Initialize\n",
        "        self.trials_in = trials_in\n",
        "        self.trials_out = trials_out\n",
        "        self.trial_ids = trial_ids\n",
        "        unique_trial_ids = np.unique(trial_ids)# get the unique ids\n",
        "        #permute to ensure mixed labels/trials in the batch and assign to object!!!\n",
        "        self.unique_trial_ids = unique_trial_ids[np.random.permutation(len(unique_trial_ids))]\n",
        "\n",
        "  def __len__(self):\n",
        "        # Size of unique trials\n",
        "        return len(self.unique_trial_ids)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        # Generates one trial\n",
        "        # Select sample\n",
        "        current_id = self.unique_trial_ids[index]\n",
        "        idx = np.where(current_id == self.trial_ids)[0]            \n",
        "        # Load data and get label\n",
        "        X = self.trials_in[idx, :]\n",
        "        Y = self.trials_out[idx, :]\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "# Task functions \n",
        "def generate_sequence_patterns(\n",
        "                               pattern_length = 3, \n",
        "                               low = 0., \n",
        "                               high = 1., \n",
        "                               nr_of_trials = 100\n",
        "                               ): \n",
        "    '''\n",
        "    Generate pattern to memorize with length N and from a uniform distribution\n",
        "    between low and high values. \n",
        "    \n",
        "    Trials have a memorize period (the generated numbers=pattern_length) \n",
        "    and a recall period, that is, 0s=pattern_length. The trials are padded with\n",
        "    zeros and ones with 1 denoting \"recall cue\". Thus, trials are 2D arrays. \n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    pattern_length: int, default 3, indicating the lenght of the pattern to\n",
        "        be memorized\n",
        "        \n",
        "    low: float, default 0., corresponding to the lowest value of the uniform\n",
        "        distribution from which random numbers are drawn\n",
        "        \n",
        "    high: float, default 1., corresponding to the highest value of the uniform\n",
        "        distribution from which random numbers are drawn    \n",
        "        \n",
        "    nr_of_trials: int, default 100, indicating the total number of trials\n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    all_input_trials: ndarray of shape (N,2) where:\n",
        "        N = ((pattern_length*2) + 1) * nr_of_trials\n",
        "        \n",
        "    all_output_trials: ndarray of shape (N,1) where:\n",
        "        N = ((pattern_length*2) + 1) * nr_of_trials\n",
        "        \n",
        "    all_trials_index: ndarray of shape (N,) where:\n",
        "        N = ((pattern_length*2) + 1) * nr_of_trials \n",
        "    '''\n",
        "    all_input_trials = None\n",
        "    all_output_trials = None\n",
        "    all_trials_index = None\n",
        "    for tr in range(nr_of_trials):\n",
        "        # Create here standard blocks of the trials, namely the cue and \"null input\"\n",
        "        # The cue is a 1 on a channel that is not used for the patterns,\n",
        "        # so concatanate a vector with 0s when we have a trial with input \n",
        "        # (the patterns to be memorized) and a 1 to denote the recall cue\n",
        "        # when the reservoir has to replay the patterns. \n",
        "        \n",
        "        # 1 is presented only once, with zeros following it for the \"null input\"   \n",
        "        null_input = np.zeros((2, pattern_length+1), dtype='float32')\n",
        "        \n",
        "        # Assign the cue at the upper left corner so that the first column of the \n",
        "        # null input is actually the recall cue.\n",
        "        null_input[0,0] = 1\n",
        "        padding_for_trial = np.zeros((pattern_length,), dtype='float32')\n",
        "        \n",
        "        #Generate one trial based on the specifications\n",
        "        trial = np.random.uniform(low, high, pattern_length)\n",
        "        trial = trial.astype('float32')\n",
        "    \n",
        "        # Add the padding that corresponds to a cue=0 (that means no replaying yet,\n",
        "        # but leanrning the input patterns)\n",
        "        trial = np.vstack((padding_for_trial, trial))\n",
        "        input_trial = np.hstack((trial, null_input))\n",
        "        \n",
        "        # Now we can construct the desired ouput. This is basically a \"mirrored\"\n",
        "        # version of the input, so construct accordingly: where null_input put\n",
        "        # the current trial and vice versa. \n",
        "        \n",
        "        # We need no padding for the output (no \"cue needed\"). Just require 0s\n",
        "        # when the pattern is being learned.\n",
        "        null_output = np.zeros((1, pattern_length+1), dtype='float32')#Add 1 column to have the same length with input\n",
        "        trial = trial[1:,:]   \n",
        "        output_trial = np.hstack((null_output, trial))\n",
        "        \n",
        "        # Concatanate the generated input/output trials to the the overall \n",
        "        # trials array \n",
        "        if all_input_trials is None:            \n",
        "            all_input_trials = input_trial\n",
        "            all_output_trials = output_trial            \n",
        "        else:            \n",
        "            all_input_trials = np.hstack((all_input_trials, input_trial))\n",
        "            all_output_trials = np.hstack((all_output_trials, output_trial))\n",
        "            \n",
        "        # Construct the indexes to keep track of the trials\n",
        "        current_index = np.zeros(input_trial.shape[1], dtype='float32')\n",
        "        current_index[:] = tr\n",
        "               \n",
        "        if all_trials_index is None:            \n",
        "            all_trials_index = current_index            \n",
        "        else:            \n",
        "            all_trials_index = np.hstack((all_trials_index, current_index))\n",
        "            \n",
        "    all_input_trials = all_input_trials.T\n",
        "    all_output_trials = all_output_trials.T\n",
        "    all_trials_index = all_trials_index.T\n",
        "        \n",
        "    return all_input_trials, all_output_trials, all_trials_index   \n",
        "\n",
        "def generate_pic_wm_trials(\n",
        "                           images = None,\n",
        "                           trial_length = 5, \n",
        "                           nr_of_trials = 100, \n",
        "                           n_back = None,\n",
        "                           trial_matching = False,\n",
        "                           rescale = True\n",
        "                           ): \n",
        "    '''\n",
        "    Generate trials of a N-Back working memory task based on 2D images\n",
        "    \n",
        "    The trials consists of consecutive images and the task is to decide\n",
        "    if the image presented last matches or not (in terms of category e.g. \n",
        "    number) the image N timesteps ago\n",
        "    \n",
        "    The trials are padded with zeros and ones with 1 denoting \"target image\" \n",
        "    cue. Thus, trials are 2D arrays\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    images: ndarray of shape (N,K,L) with N the number of images, and K and L\n",
        "        the dimensions of the image\n",
        "        \n",
        "        images contain values in the [0 255] range\n",
        "        \n",
        "        As a default the MNIST dataset, asprepackaged in Keras, is used.\n",
        "        Thus, N=10000 K=28 L=28 and datatype is unit8\n",
        "        \n",
        "        However, any image dataset can be passed as an argument given that it\n",
        "        complies with the aformentioned format\n",
        "\n",
        "    trial_length: int, default 5, indicating the lenght of the trial, \n",
        "        specifically the number of images that are used in the memorization \n",
        "        phase of the task. The image corresponding to the latest timestep is \n",
        "        always the target image. For instance if trial_length=5, them the 5th\n",
        "        image is the target\n",
        "     \n",
        "    nr_of_trials: int, default 100, indicating the total number of trials    \n",
        "    \n",
        "    n_back: int specifying the match N timesteps before the last image. For\n",
        "        instance, if n_back=2, then the image that should be compared with the \n",
        "        target image is the 3rd image in the trial\n",
        "        \n",
        "    trial_matching: bool, default False, specifying if the trials to be \n",
        "        generated should be matching trials(=True) or non-matching trials \n",
        "        (=False) \n",
        "        \n",
        "    rescale: bool, default True, specifying if the images should be rescaled\n",
        "        by dividing with 255\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    all_input_trials: ndarray of shape (N,M) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials\n",
        "        M = (K*L)+1 (image size + 1)\n",
        "        \n",
        "    all_output_trials: ndarray of shape (N,1) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials\n",
        "        \n",
        "    all_trials_index: ndarray of shape (N,) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials        \n",
        "    '''\n",
        "    if ((trial_length-n_back) <=0) and (n_back is not None):\n",
        "        raise ValueError('N-Back value must be less than the trial length')\n",
        "           \n",
        "    all_input_trials = None\n",
        "    all_output_trials = None\n",
        "    all_trials_index = None\n",
        "        \n",
        "    img_pixels = images.shape[1]*images.shape[2] \n",
        "    \n",
        "    for tr in range(nr_of_trials):\n",
        "        # Create here standard blocks of the trials, namely the cue and \"null input\"\n",
        "        # The cue is a 1 on a channel that is not used for the patterns,\n",
        "        # so concatanate a vector with 0s when we have a trial with input \n",
        "        # (the patterns to be memomorized) and a 1 to denote the recall cue\n",
        "        # when the reservoir has to replay the patterns. \n",
        "        \n",
        "        # 1 is presented only once, with zeros following it for the \"null input\" \n",
        "        null_input = np.zeros((img_pixels+1, 2))\n",
        "        \n",
        "        # Assign the cue at the upper left corner so that the first column of the \n",
        "        # null input is actually the recall cue.\n",
        "        null_input[0,0] = 1\n",
        "        \n",
        "        padding_for_trial = np.zeros((trial_length,))\n",
        "        \n",
        "        #Generate one trial based on the specifications\n",
        "        # The last pic in the trial must be also the pic n_back steps\n",
        "        target_pic_idx = random.randrange(images.shape[0])\n",
        "        trial = np.zeros((img_pixels, trial_length))\n",
        "        \n",
        "        #Mark the positions of the target picture with 1s and assign the \n",
        "        #target pic in the correct indexes indicated by len(trial_idxs) and\n",
        "        #n_back. Take into account if the trials are \n",
        "        #trial_matching = True or False\n",
        "        trial_idxs = np.zeros((trial_length,))\n",
        "        \n",
        "        if trial_matching is True:\n",
        "            trial_idxs[len(trial_idxs)-1] = 1\n",
        "            trial_idxs[(len(trial_idxs)-1) - n_back] = 1\n",
        "            trial[:, len(trial_idxs)-1] =  images[target_pic_idx, :, :].reshape(img_pixels,)\n",
        "            trial[:, (len(trial_idxs)-1) - n_back] =  images[target_pic_idx, :, :].reshape(img_pixels,)\n",
        "        else:\n",
        "            trial_idxs[len(trial_idxs)-1] = 1\n",
        "            trial[:, len(trial_idxs)-1] =  images[target_pic_idx, :, :].reshape(img_pixels,) \n",
        "        \n",
        "        random_pic_idx = random.sample(range(0, images.shape[0]-1), \n",
        "                                       len(np.where(trial_idxs == 0)[0]))\n",
        "    \n",
        "        rand_pic_idxs = np.where(trial_idxs == 0)[0]\n",
        "    \n",
        "        for i in range (len(random_pic_idx)):\n",
        "           trial[:,rand_pic_idxs[i]] = images[random_pic_idx[i], :, :].reshape(img_pixels,)\n",
        "    \n",
        "        #Rescale to 255 if rescale True\n",
        "        if rescale is True:\n",
        "            trial = trial/255\n",
        "    \n",
        "        # Add the padding that corresponds to a cue=0 \n",
        "        #(that means no replaying yet, but learning the input patterns)\n",
        "        trial = np.vstack((padding_for_trial, trial))\n",
        "        \n",
        "        input_trial = np.hstack((trial, null_input))\n",
        "        \n",
        "        # Now we can construct the desired ouput. \n",
        "        # What we need is an array with input_trial shape with 3 discrete\n",
        "        # values: \n",
        "        # 0:fixation \n",
        "        # 1:n_back matches=False\n",
        "        # 2:n_back matches=True\n",
        "        # Hence, the output trials correspond to the correct labels of \n",
        "        # a 3-class classification problem\n",
        "        output_trial = np.zeros((1, trial_length+2))#Add 1 column to have the same length with input\n",
        "        \n",
        "        #Assign the correct labeling\n",
        "        \n",
        "        if trial_matching is True:\n",
        "            output_trial[0, (trial_length+1):] = 2\n",
        "        else:\n",
        "            output_trial[0, (trial_length+1):] = 1\n",
        "        \n",
        "        # Concatanate the generated input/output trials to the overall \n",
        "        # trials array \n",
        "        if all_input_trials is None:       \n",
        "            all_input_trials = input_trial\n",
        "            all_output_trials = output_trial       \n",
        "        else:       \n",
        "            all_input_trials = np.hstack((all_input_trials, input_trial))\n",
        "            all_output_trials = np.hstack((all_output_trials, output_trial))\n",
        "            \n",
        "        # Construct the indexes to keep track of the trials\n",
        "        current_index = np.zeros(input_trial.shape[1],)\n",
        "        current_index[:] = tr\n",
        "        \n",
        "        \n",
        "        if all_trials_index is None:          \n",
        "            all_trials_index = current_index          \n",
        "        else:          \n",
        "            all_trials_index = np.hstack((all_trials_index, current_index))\n",
        "            \n",
        "    all_input_trials = all_input_trials.T\n",
        "    all_output_trials = all_output_trials.T\n",
        "    \n",
        "    all_trials_index = all_trials_index.T\n",
        "          \n",
        "    return all_input_trials, all_output_trials, all_trials_index  \n",
        "\n",
        "def generate_pic_latent_wm_trials( \n",
        "                                  images = None,\n",
        "                                  labels = None,\n",
        "                                  trial_length = 5, \n",
        "                                  nr_of_trials = 100, \n",
        "                                  n_back = None,\n",
        "                                  trial_matching = False,\n",
        "                                  rescale = True\n",
        "                                  ): \n",
        "    '''\n",
        "    Generate trials of a N-Back working memory task based on 2D images that \n",
        "    are first fed into a CONVNET.\n",
        "    \n",
        "    The trials consists of consecutive images and the task is to decide\n",
        "    if the image presented last matches or not (in terms of category e.g. \n",
        "    number) the image N timesteps ago\n",
        "    \n",
        "    The trials are padded with zeros and ones with 1 denoting \"target image\" \n",
        "    cue. Thus, trials are 2D arrays\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    images: torch.Tensor of shape (N,K) with N the number of images, and K\n",
        "        the dimensions of the image in the latent space of the CNVNET\n",
        "                \n",
        "    trial_length: int, default 5, indicating the lenght of the trial, \n",
        "        specifically the number of images that are used in the memorization \n",
        "        phase of the task. The image corresponding to the latest timestep is \n",
        "        always the target image. For instance if trial_length=5, them the 5th\n",
        "        image is the target\n",
        "     \n",
        "    nr_of_trials: int, default 100, indicating the total number of trials    \n",
        "    \n",
        "    n_back: int specifying the match N timesteps before the last image. For\n",
        "        instance, if n_back=2, then the image that should be compared with the \n",
        "        target image is the 3rd image in the trial\n",
        "        \n",
        "    trial_matching: bool, default False, specifying if the trials to be \n",
        "        generated should be matching trials(=True) or non-matching trials \n",
        "        (=False) \n",
        "        \n",
        "    rescale: bool, default True, specifying if the images should be rescaled\n",
        "        to the [0 1] range\n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    all_input_trials: ndarray of shape (N,M) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials\n",
        "        M = (K+1 (latent space size + 1)\n",
        "        \n",
        "    all_output_trials: ndarray of shape (N,1) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials\n",
        "        \n",
        "    all_trials_index: ndarray of shape (N,) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials    \n",
        "    \n",
        "    '''\n",
        "    if ((trial_length-n_back) <=0) and (n_back is not None):\n",
        "        raise ValueError('N-Back value must be less than the trial length')\n",
        "           \n",
        "    all_input_trials = None\n",
        "    all_output_trials = None\n",
        "    all_trials_index = None\n",
        "        \n",
        "    img_size = images.shape[1]\n",
        "    #Rescale to [0 1] if rescale True\n",
        "    if rescale is True:\n",
        "        images = scale_tensor(images, \n",
        "                                     global_scaling = False\n",
        "                                     )# rescale each trial seperately (row-wise rescaling)\n",
        "    \n",
        "    # Convert to numpy\n",
        "    images = images.clone().numpy()\n",
        "    labels = labels.clone().numpy()\n",
        "\n",
        "    # Keep unique labels\n",
        "    unique_labels = np.unique(labels)    \n",
        "    for tr in range(nr_of_trials):\n",
        "        # Create here standard blocks of the trials, namely the cue and \"null input\"\n",
        "        # The cue is a 1 on a channel that is not used for the patterns,\n",
        "        # so concatanate a vector with 0s when we have a trial with input \n",
        "        # (the patterns to be memomorized) and a 1 to denote the recall cue\n",
        "        # when the reservoir has to replay the patterns. \n",
        "        \n",
        "        # 1 is presented only once, with zeros following it for the \"null input\" \n",
        "        null_input = np.zeros((img_size+1, 2), dtype = 'float32')\n",
        "        \n",
        "        # Assign the cue at the upper left corner so that the first column of the \n",
        "        # null input is actually the recall cue.\n",
        "        null_input[0,0] = 1\n",
        "        \n",
        "        padding_for_trial = np.zeros((trial_length,), dtype = 'float32')\n",
        "        \n",
        "        # Generate one trial based on the specifications\n",
        "        # The last pic in the trial must be also the pic n_back steps\n",
        "        # Select the targets and the non-targets based on the labels\n",
        "        target_pic_label = random.randrange(unique_labels.shape[0])\n",
        "        trial = np.zeros((img_size, trial_length), dtype = 'float32')\n",
        "        \n",
        "        potential_target_pic_idxs = np.where(target_pic_label == labels)[0]\n",
        "        potential_non_target_pic_idxs = np.where(target_pic_label != labels)[0]\n",
        "        \n",
        "        target_pic_idx = random.sample(list(potential_target_pic_idxs), 1)\n",
        "        target_pic = images[target_pic_idx, :]\n",
        "        \n",
        "        # Remove the index of the used pic from the pool of potential targets\n",
        "        potential_target_pic_idxs = potential_target_pic_idxs[np.where(\n",
        "                                                              potential_target_pic_idxs != target_pic_idx\n",
        "                                                              )[0]\n",
        "                                                             ]\n",
        "        \n",
        "        #Mark the positions of the target picture with 1s and assign the \n",
        "        #target pic in the correct indexes indicated by len(trial_idxs) and\n",
        "        #n_back. Take into account if the trials are \n",
        "        #trial_matching = True or False\n",
        "        trial_idxs = np.zeros((trial_length,), dtype = 'float32')\n",
        "        \n",
        "        if trial_matching is True:\n",
        "            trial_idxs[len(trial_idxs)-1] = 1\n",
        "            trial_idxs[(len(trial_idxs)-1) - n_back] = 1\n",
        "            trial[:, len(trial_idxs)-1] = target_pic\n",
        "            trial[:, (len(trial_idxs)-1) - n_back] = target_pic\n",
        "        else:\n",
        "            trial_idxs[len(trial_idxs)-1] = 1\n",
        "            trial[:, len(trial_idxs)-1] = target_pic\n",
        "        \n",
        "        rand_pic_in_trial_idxs = np.where(trial_idxs == 0)[0]\n",
        "        \n",
        "        random_pic_idx = random.sample(list(potential_non_target_pic_idxs), \n",
        "                                       len(rand_pic_in_trial_idxs)\n",
        "                                       )\n",
        "  \n",
        "        for i in range (len(random_pic_idx)):\n",
        "           trial[:, rand_pic_in_trial_idxs[i]] = images[random_pic_idx[i], :]\n",
        "     \n",
        "        # Remove from the pool of potential random pic_idx the used pics   \n",
        "        remove_pic_idxs = np.in1d(potential_non_target_pic_idxs, random_pic_idx).nonzero()[0]\n",
        "        potential_non_target_pic_idxs = np.delete(potential_non_target_pic_idxs, \n",
        "                                                  remove_pic_idxs\n",
        "                                                  )   \n",
        "                     \n",
        "        # Add the padding that corresponds to a cue=0 \n",
        "        #(that means no replaying yet, but learning the input patterns)\n",
        "        trial = np.vstack((padding_for_trial, trial))\n",
        "        input_trial = np.hstack((trial, null_input))\n",
        "        \n",
        "        # Now we can construct the desired ouput. \n",
        "        # What we need is an array with input_trial shape with 3 discrete\n",
        "        # values: \n",
        "        # 0:fixation \n",
        "        # 1:n_back matches=False\n",
        "        # 2:n_back matches=True\n",
        "        # Hence, the output trials correspond to the correct labels of \n",
        "        # a 3-class classification problem\n",
        "        output_trial = np.zeros((1, trial_length+2), dtype = 'float32')#Add 1 column to have the same length with input\n",
        "        \n",
        "        #Assign the correct labeling\n",
        "        if trial_matching is True:\n",
        "            output_trial[0, (trial_length+1):] = 2\n",
        "        else:\n",
        "            output_trial[0, (trial_length+1):] = 1\n",
        "        \n",
        "        # Concatanate the generated input/output trials to the overall \n",
        "        # trials array \n",
        "        if all_input_trials is None:          \n",
        "            all_input_trials = input_trial\n",
        "            all_output_trials = output_trial          \n",
        "        else:          \n",
        "            all_input_trials = np.hstack((all_input_trials, input_trial))\n",
        "            all_output_trials = np.hstack((all_output_trials, output_trial))\n",
        "            \n",
        "        # Construct the indexes to keep track of the trials\n",
        "        current_index = np.zeros(input_trial.shape[1], dtype = 'float32')\n",
        "        current_index[:] = tr\n",
        "              \n",
        "        if all_trials_index is None:           \n",
        "            all_trials_index = current_index           \n",
        "        else:           \n",
        "            all_trials_index = np.hstack((all_trials_index, current_index))\n",
        "            \n",
        "    all_input_trials = all_input_trials.T\n",
        "    all_output_trials = all_output_trials.T\n",
        "    \n",
        "    all_trials_index = all_trials_index.T\n",
        "          \n",
        "    return all_input_trials, all_output_trials, all_trials_index  \n",
        "\n",
        "def generate_nback_wm_trials(\n",
        "                            trial_length = 5, \n",
        "                            nr_of_trials = 100, \n",
        "                            n_back = None,\n",
        "                            trial_matching = False\n",
        "                            ):\n",
        "    '''\n",
        "    Generate trials of a N-Back working memory task based on a sequence of\n",
        "    numbers from a random uniform distribution [0 1]\n",
        "    \n",
        "    The trials consists of numbers and the task is to decide\n",
        "    if the number presented last matches or not the number N timesteps ago\n",
        "    \n",
        "    The trials are padded with zeros and ones with 1 denoting \"target number\" \n",
        "    cue. Thus, trials are 2D arrays\n",
        "\n",
        "    trial_length: int, default 5, indicating the lenght of the trial, \n",
        "        specifically the number of number that are used in the memorization \n",
        "        phase of the task. The number corresponding to the latest timestep is \n",
        "        always the target number. For instance if trial_length=5, them the 5th\n",
        "        number is the target\n",
        "    \n",
        "    nr_of_trials: int, default 100, indicating the total number of trials  \n",
        "    \n",
        "    n_back: int specifying the match N timesteps before the last number. For\n",
        "        instance, if n_back=2, then the number that should be compared with the \n",
        "        target number is the 3rd number in the trial\n",
        "        \n",
        "    trial_matching: bool, default False, specifying if the trials to be \n",
        "        generated should be matching trials(=True) or non-matching trials \n",
        "        (=False) \n",
        "    \n",
        "    Output\n",
        "    ------\n",
        "    all_input_trials: ndarray of shape (N,2) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials\n",
        "        \n",
        "    all_output_trials: ndarray of shape (N,1) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials\n",
        "        \n",
        "    all_trials_index: ndarray of shape (N,) where:\n",
        "        N = ((trial_length*2) + 1) * nr_of_trials\n",
        "    '''\n",
        "    if ((trial_length-n_back) <=0) and (n_back is not None):\n",
        "        raise ValueError('N-Back value must be less than the trial length')\n",
        "           \n",
        "    all_input_trials = None\n",
        "    all_output_trials = None\n",
        "    \n",
        "    all_trials_index = None\n",
        "    \n",
        "    for tr in range(nr_of_trials):\n",
        "        # Create here standard blocks of the trials, namely the cue and \"null input\"\n",
        "        # The cue is a 1 on a channel that is not used for the patterns,\n",
        "        # so concatanate a vector with 0s when we have a trial with input \n",
        "        # (the patterns to be memomorized) and a 1 to denote the recall cue\n",
        "        # when the reservoir has to replay the patterns. \n",
        "        \n",
        "        # 1 is presented only once, with zeros following it for the \"null input\" \n",
        "        null_input = np.zeros((2, 1), dtype='float32')\n",
        "        \n",
        "        # Assign the cue at the upper left corner so that the first column of the \n",
        "        # null input is actually the recall cue.\n",
        "        #null_input[0,0] = 1\n",
        "        \n",
        "        padding_for_trial = np.zeros((trial_length,), dtype='float32')\n",
        "        padding_for_trial[-1] = 1.\n",
        "        \n",
        "        #Generate one trial based on the specifications\n",
        "        # The last pic in the trial must be also the pic n_back steps\n",
        "        #target_pic_idx = random.randrange(x_train.shape[0])\n",
        "        \n",
        "        #trial = np.zeros((1, trial_length))\n",
        "        trial = np.random.uniform(0., 1., trial_length)\n",
        "        trial = trial.astype('float32')\n",
        "        trial = np.reshape(trial, (1, trial_length))\n",
        "        \n",
        "        #Mark the positions of the target picture with 1s and assign the \n",
        "        #target pic in the correct indexes indicated by len(trial_idxs) and\n",
        "        #n_back. Take into account if the trials are \n",
        "        #trial_matching = True or False\n",
        "        #trial_idxs = np.zeros((trial_length,))\n",
        "         \n",
        "        #target_value = random.sample(range(0, 2), 1)\n",
        "        target_value = np.random.uniform(0., 1., 1)\n",
        "        target_value = target_value.astype('float32')\n",
        "        if trial_matching is True:\n",
        "            trial[0, trial_length-1] = target_value[0]\n",
        "            trial[0, (trial_length-n_back-1)] = target_value[0]\n",
        "        else:\n",
        "            trial[0, trial_length-1] =  target_value[0]\n",
        "            \n",
        "        # Add the padding that corresponds to a cue=0 \n",
        "        #(that means no replaying yet, but learning the input patterns)\n",
        "        trial = np.vstack((padding_for_trial, trial))\n",
        "        \n",
        "        input_trial = np.hstack((trial, null_input))\n",
        "        \n",
        "        # Now we can construct the desired ouput. \n",
        "        # What we need is an array with input_trial shape with 3 discrete\n",
        "        # values: \n",
        "        # 0:fixation \n",
        "        # 1:n_back matches=False\n",
        "        # 2:n_back matches=True\n",
        "        # Hence, the output trials correspond to the correct labels of \n",
        "        # a 3-class classification problem\n",
        "        output_trial = np.zeros((1, trial_length+1), dtype = 'float32')#Add 1 column to have the same length with input\n",
        "        \n",
        "        #Assign the correct labeling\n",
        "        if trial_matching is True:\n",
        "            output_trial[0, trial_length] = 2\n",
        "        else:\n",
        "            output_trial[0, trial_length] = 1\n",
        "        \n",
        "        # Concatanate the generated input/output trials to the the overall \n",
        "        # trials array \n",
        "        if all_input_trials is None:     \n",
        "            all_input_trials = input_trial\n",
        "            all_output_trials = output_trial \n",
        "        else:\n",
        "            \n",
        "            all_input_trials = np.hstack((all_input_trials, input_trial))\n",
        "            all_output_trials = np.hstack((all_output_trials, output_trial))\n",
        "            \n",
        "        # Construct the indexes to keep track of the trials\n",
        "        current_index = np.zeros(input_trial.shape[1], dtype = 'float32')\n",
        "        current_index[:] = tr\n",
        "               \n",
        "        if all_trials_index is None:           \n",
        "            all_trials_index = current_index           \n",
        "        else:           \n",
        "            all_trials_index = np.hstack((all_trials_index, current_index))\n",
        "            \n",
        "    all_input_trials = all_input_trials.T\n",
        "    all_output_trials = all_output_trials.T\n",
        "    \n",
        "    all_trials_index = all_trials_index.T\n",
        "           \n",
        "    return all_input_trials, all_output_trials, all_trials_index \n",
        "\n",
        "def wrapper_trials(func):\n",
        "    '''\n",
        "    Decorator function used to generate trials by setting the \n",
        "    trial_matching parameter to False and subsequently True\n",
        "    (Used from create_trials()) \n",
        "    '''\n",
        "    def internal(**kwargs):\n",
        "        print('Generating trials with params:')\n",
        "        for key in kwargs:\n",
        "            if key not in ['images', 'labels']:\n",
        "                print('%s: %s' % (key, kwargs[key]))\n",
        "        \n",
        "        # Call the function with 'trial_matching':True\n",
        "        kwargs.update({'trial_matching':True})    \n",
        "        X_match, Y_match, indexes_match=func(**kwargs)  \n",
        "            \n",
        "        # Call the function with 'trial_matching':False\n",
        "        kwargs.update({'trial_matching':False})  \n",
        "        X_non_match, Y_non_match, indexes_non_match=func(**kwargs)\n",
        "        \n",
        "        print('Generating trials with params:')\n",
        "        for key in kwargs:\n",
        "             if key not in ['images', 'labels']:\n",
        "                print('%s: %s' % (key, kwargs[key]))\n",
        "        \n",
        "        # Increase the indexes_non_match in such a way so that they are \n",
        "        # a continuation of the indexes_match \n",
        "        indexes_non_match  +=  np.max(indexes_match)+1\n",
        "        \n",
        "        # Concatanate all true and false trials\n",
        "        X = np.vstack((X_match, X_non_match))\n",
        "        Y = np.vstack((Y_match, Y_non_match))\n",
        "        indexes = np.hstack((indexes_match, indexes_non_match))\n",
        "        \n",
        "        return  X,Y,indexes\n",
        "        \n",
        "    return internal\n",
        "\n",
        "def create_train_test_trials(\n",
        "                             X = None,\n",
        "                             Y = None,\n",
        "                             indexes = None,\n",
        "                             train_size = 0.8\n",
        "                             ):\n",
        "    '''\n",
        "    Create train and test sets\n",
        "    (this is just a wrapper around scikit-learn's GroupShuffleSplit)\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    X: ndarray of shape (N,M) representing a feature matrix\n",
        "        with N observations and M features (representing trials)\n",
        "    \n",
        "    Y: ndarray of shape (N,) of labels (representing task output)\n",
        "\n",
        "    indexes: ndarray of shape (N,) with unique numbers (float or int) grouping\n",
        "        together the observations constituting one trial\n",
        "        These indexes will be used by  thr group shuffle split\n",
        "     \n",
        "    train_size: float (0 1), default 0.8, denoting the percentage of X to be \n",
        "        used for the train set \n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    X: list of len 2 containing the train X[0] and test set X[1]\n",
        "        \n",
        "    Y: list of len 2 containing the train Y[0] and test set Y[1] labels \n",
        "        \n",
        "    indexes: list of len 2 containing the train indexes[0] and test set \n",
        "    indexes[1] indexes. These indexes correspond to the indexes parameter  \n",
        "    '''\n",
        "    # Create train and validate tests by ensuring that only complete \n",
        "    # trials are shuffled!\n",
        "    gss = GroupShuffleSplit(n_splits=1, train_size=train_size)\n",
        "    \n",
        "    for train_idx, validate_idx in gss.split(X, Y, indexes):\n",
        "        X_train = X[train_idx]   \n",
        "        Y_train = Y[train_idx]  \n",
        "        \n",
        "        X_validate = X[validate_idx]   \n",
        "        Y_validate = Y[validate_idx]\n",
        "    \n",
        "    # Seperate idx for train and validate sets \n",
        "    train_trial_idxs = indexes[train_idx]\n",
        "    validate_trial_idxs = indexes[validate_idx] \n",
        "\n",
        "    # Wrap up results in lists. Each position corresponds to train\n",
        "    # validate sets   \n",
        "    X = [X_train, X_validate]\n",
        "    Y = [Y_train, Y_validate]\n",
        "    indexes = [train_trial_idxs, validate_trial_idxs]\n",
        "    \n",
        "    return X, Y, indexes\n",
        "    \n",
        "def trim_zeros_from_trials(actual=None, predicted=None):\n",
        "    '''\n",
        "    Remove zeros in-between experimental trials. This is useful to remove \n",
        "    \"fixation\" periods from trials and thus do not take into account \n",
        "    such perios in the calculation of the error (and thus the training of the \n",
        "    network)\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    actual: torch.Tensor of shape (N,M) where N is the length of the experiement\n",
        "        and M the dimensions involved with a specific experiment. \n",
        "        NOTE: the function will remove the observations from N that are \n",
        "        equal to 0\n",
        "        \n",
        "    predicted: torch.Tensor of shape (N,K) here N is the length of the experiement\n",
        "        and K the dimensions involved with a specific experimental \n",
        "        output/prediction \n",
        "        \n",
        "    Output\n",
        "    ------\n",
        "    actual_trimmed:  torch.Tensor of shape (N-P,M) where N-P is the length of \n",
        "        the experiement after the removal of 0s from actual[:,0],\n",
        "        and M the dimensions involved with a specific experiment.\n",
        "        \n",
        "    predicted_trimmed: torch.Tensor of shape (N-P,K) where N-P is the length of \n",
        "        the experiement after the removal of 0s from actual[:,0],\n",
        "        and K the dimensions involved with a specific experimental \n",
        "        output/prediction        \n",
        "    '''\n",
        "    ind = torch.where(actual != 0)[0]#use the actual trials for tracking non 0s \n",
        "    actual_trimmed = actual[ind]\n",
        "    predicted_trimmed = predicted[ind]    \n",
        "    \n",
        "    return actual_trimmed, predicted_trimmed  \n",
        "\n",
        "def create_trials(trial_params):\n",
        "    '''\n",
        "    Create trials that correspond to the experimental design specified in the \n",
        "    dictionary trial_params\n",
        "    \n",
        "    Input\n",
        "    -----\n",
        "    trial_params: dict with trial parameters for a task\n",
        "        key: 'task_name'    value: {'nback_mem','seq_mem', 'pic_mem', 'pic_latent_mem'}\n",
        "             'nr_of_trials'        int\n",
        "             'trial_length'        int\n",
        "             'trial_matching'      bool\n",
        "             'train_size'          float (0 1)\n",
        "             'n_back'              int (if 'task_name'={'nback_mem', 'pic_mem', 'pic_latent_mem'})\n",
        "    \n",
        "    '''\n",
        "    if trial_params['task_name'] == 'seq_mem':\n",
        "        pattern_length = trial_params['pattern_length']\n",
        "        nr_of_trials = trial_params['nr_of_trials']\n",
        "        train_size = trial_params['train_size']\n",
        "        \n",
        "        # Train and validation test\n",
        "        (X, \n",
        "         Y,\n",
        "         indexes) = generate_sequence_patterns(pattern_length = pattern_length, \n",
        "                                               nr_of_trials = nr_of_trials\n",
        "                                               ) \n",
        "                                               \n",
        "    if trial_params['task_name'] == 'pic_mem':  \n",
        "        # Load the data\n",
        "        from keras.datasets import mnist#Load mnist from keras \n",
        "        # Use only the test set - it has \n",
        "        # less but sufficient samples than the train\n",
        "        _ , (x_test, y_test) = mnist.load_data() \n",
        "        \n",
        "        nr_of_trials = trial_params['nr_of_trials']\n",
        "        trial_length = trial_params['trial_length']\n",
        "        n_back = trial_params['n_back']\n",
        "        trial_matching = trial_params['trial_matching']\n",
        "        rescale = trial_params['rescale']\n",
        "        \n",
        "        train_size = trial_params['train_size'] \n",
        "        \n",
        "        generate_pic_wm_trials_boosted = wrapper_trials(generate_pic_wm_trials)\n",
        "        \n",
        "        X, Y, indexes = generate_pic_wm_trials_boosted(images = x_test,\n",
        "                                                       trial_length = trial_length, \n",
        "                                                       nr_of_trials = nr_of_trials, \n",
        "                                                       n_back = n_back,\n",
        "                                                       trial_matching = trial_matching,\n",
        "                                                       rescale = rescale\n",
        "                                                       )\n",
        "        \n",
        "    if trial_params['task_name'] == 'pic_latent_mem':  \n",
        "        # Load the data\n",
        "        # Use only the test set - it has \n",
        "        # less but sufficient samples than the train\n",
        "        output, labels = torch.load('latent_mnist/mnist_latent_output_labels.pt') \n",
        "        \n",
        "        nr_of_trials = trial_params['nr_of_trials']\n",
        "        trial_length = trial_params['trial_length']\n",
        "        n_back = trial_params['n_back']\n",
        "        trial_matching = trial_params['trial_matching']\n",
        "        rescale = trial_params['rescale']\n",
        "        \n",
        "        train_size = trial_params['train_size'] \n",
        "        \n",
        "        generate_pic_wm_trials_boosted = wrapper_trials(generate_pic_latent_wm_trials)\n",
        "        \n",
        "        X, Y, indexes = generate_pic_wm_trials_boosted(images = output,\n",
        "                                                       labels = labels,\n",
        "                                                       trial_length = trial_length, \n",
        "                                                       nr_of_trials = nr_of_trials, \n",
        "                                                       n_back = n_back,\n",
        "                                                       trial_matching = trial_matching,\n",
        "                                                       rescale = rescale\n",
        "                                                       )    \n",
        "        \n",
        "    if trial_params['task_name'] == 'nback_mem': \n",
        "        nr_of_trials = trial_params['nr_of_trials']\n",
        "        trial_length = trial_params['trial_length']\n",
        "        n_back = trial_params['n_back']\n",
        "        trial_matching = trial_params['trial_matching']\n",
        "        \n",
        "        train_size = trial_params['train_size'] \n",
        "        \n",
        "        generate_bin_wm_trials_boosted = wrapper_trials(generate_nback_wm_trials)\n",
        "        \n",
        "        X, Y, indexes = generate_bin_wm_trials_boosted(trial_length = trial_length, \n",
        "                                                       nr_of_trials = nr_of_trials, \n",
        "                                                       n_back = n_back,\n",
        "                                                       trial_matching = trial_matching,\n",
        "                                                       )\n",
        "                                                                                                                                                                                                                \n",
        "    # Create train and validate tests by ensuring that only complete trials\n",
        "    # are shuffled!                                        \n",
        "    X, Y, indexes = create_train_test_trials(X = X,\n",
        "                                             Y = Y,\n",
        "                                             indexes = indexes,\n",
        "                                             train_size = train_size\n",
        "                                             )\n",
        "    \n",
        "    X[0], Y[0], indexes[0] = group_shuffle(X[0], Y[0], indexes[0])\n",
        "    X[1], Y[1], indexes[1] = group_shuffle(X[1], Y[1], indexes[1])\n",
        "    \n",
        "    return X, Y, indexes"
      ],
      "metadata": {
        "id": "MRLsPnGpgHUO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import snntorch as snn\n",
        "from snntorch import surrogate\n",
        "from snntorch import spikeplot as splt\n",
        "from snntorch import spikegen\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools"
      ],
      "metadata": {
        "id": "NrhybCkNDUMV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader arguments\n",
        "batch_size = 1\n",
        "params_generators = {\n",
        "                     'batch_size': 1,\n",
        "                     'shuffle': False,\n",
        "                     'num_workers': 0\n",
        "                     }\n",
        "\n",
        "trial_params = {\"task_name\":\"nback_mem\", \"nr_of_trials\":50, \"trial_length\":5, \"train_size\":0.8, \"n_back\":1, \"trial_matching\": True}\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "Dqq-5LWcZmp7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y, trials_idx = create_trials(trial_params)\n",
        " #Set dataloaders\n",
        "training_set = Dataset(X[0], Y[0], trials_idx[0])\n",
        "train_loader = DataLoader(training_set, **params_generators)\n",
        "validate_set = Dataset(X[1], Y[1], trials_idx[1])\n",
        "test_loader = DataLoader(validate_set, **params_generators)\n",
        "# train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "# test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BtOT-BlZsHz",
        "outputId": "bb51dae4-bed1-4820-ae8a-421b1ec76dcb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating trials with params:\n",
            "trial_length: 5\n",
            "nr_of_trials: 50\n",
            "n_back: 1\n",
            "trial_matching: True\n",
            "Generating trials with params:\n",
            "trial_length: 5\n",
            "nr_of_trials: 50\n",
            "n_back: 1\n",
            "trial_matching: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Network Architecture\n",
        "num_inputs = 2\n",
        "num_hidden1 = 2\n",
        "num_hidden2 = 3\n",
        "num_output = 3\n",
        "\n",
        "# Temporal Dynamics\n",
        "num_steps = 5\n",
        "beta = 0.5"
      ],
      "metadata": {
        "id": "Pd8--RynEOJI"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        spike_grad_lstm = surrogate.straight_through_estimator()\n",
        "\n",
        "        # initialize layers\n",
        "        self.slstm1 = snn.SLSTM(num_inputs, num_hidden1, spike_grad=spike_grad_lstm)\n",
        "        self.slstm2 = snn.SLSTM(num_hidden1, num_hidden2, spike_grad=spike_grad_lstm)\n",
        "        self.fc = nn.Linear(num_hidden2, num_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden states and outputs at t=0\n",
        "        syn1, mem1 = self.slstm1.init_slstm()\n",
        "        syn2, mem2 = self.slstm2.init_slstm()\n",
        "\n",
        "        # Record the final layer\n",
        "        spk2_rec = []\n",
        "        mem2_rec = []\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            spk1, syn1, mem1 = self.slstm1(x.flatten(1), syn1, mem1)\n",
        "            spk2, syn2, mem2 = self.slstm2(spk1, syn2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2)\n",
        "            mem2_rec.append(mem2)\n",
        "        \n",
        "\n",
        "        return torch.stack(spk2_rec), torch.stack(mem2_rec)\n",
        "\n",
        "net = Net().to(device)"
      ],
      "metadata": {
        "id": "MpXvZwPQDWnw"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass data into the network, sum the spikes over time\n",
        "# and compare the neuron with the highest number of spikes\n",
        "# with the target\n",
        "\n",
        "def print_batch_accuracy(data, targets, train=False):\n",
        "    # output, _ = net(data)\n",
        "    output, _ = net(data.view(batch_size, -1))\n",
        "    _, idx = output.sum(dim=0).max(1)\n",
        "    print(data)\n",
        "    print(output)\n",
        "    print(idx)\n",
        "    print(targets)\n",
        "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
        "\n",
        "    if train:\n",
        "        print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "    else:\n",
        "        print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
        "\n",
        "def train_printer(\n",
        "    data, targets, epoch,\n",
        "    counter, iter_counter,\n",
        "        loss_hist, test_loss_hist, test_data, test_targets):\n",
        "    print(f\"Epoch {epoch}, Iteration {iter_counter}\")\n",
        "    print(f\"Train Set Loss: {loss_hist[counter]:.2f}\")\n",
        "    print(f\"Test Set Loss: {test_loss_hist[counter]:.2f}\")\n",
        "    print_batch_accuracy(data, targets, train=True)\n",
        "    print_batch_accuracy(test_data, test_targets, train=False)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "Ijs7dc5JEmK7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "# loss = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "uAHE01nJZ1iM"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))"
      ],
      "metadata": {
        "id": "3AIQgTMuZ3-Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "loss_hist = []\n",
        "test_loss_hist = []\n",
        "counter = 0"
      ],
      "metadata": {
        "id": "H7M7PLvPaLin"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_train_loss=[]\n",
        "epoch_train_loss_null=[]\n",
        "\n",
        "epoch_train_metrics=[]\n",
        "epoch_train_metrics_null=[]\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  batch_loss = []\n",
        "\n",
        "  for X_batch, Y_batch in train_loader:\n",
        "    print(X_batch[0])\n",
        "    X_batch, Y_batch = X_batch[0].to(device), Y_batch.to(device)\n",
        "    optimizer.zero_grad()#clear existing gradients from previous batch                       \n",
        "\n",
        "    output, mem_rec = net(X_batch) \n",
        "    # output, mem_rec = net(X_batch.view(batch_size, -1))\n",
        "\n",
        "    Y_batch = Y_batch.contiguous().view(\n",
        "        int(batch_size * (len(output)/batch_size)), \n",
        "        -1)\n",
        "    \n",
        "    Y_batch, output = trim_zeros_from_trials(actual=Y_batch, predicted=output)\n",
        "    Y_batch = Y_batch.view(Y_batch.shape[1],)\n",
        "    # Y_batch = Y_batch.type(torch.LongTensor)\n",
        "\n",
        "    output = output.view(output.shape[2],)\n",
        "    # output = output.type(torch.LongTensor)\n",
        "\n",
        "    loss_val = loss(output, Y_batch)\n",
        "    batch_loss.append(loss_val.data.item())\n",
        "\n",
        "    loss_val.backward()\n",
        "    optimizer.step()\n",
        "    print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "tJxy02kKolJz",
        "outputId": "cb69345e-8a2d-48e4-dac8-bebe3986aba3"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 0.2970],\n",
            "        [0.0000, 0.5895],\n",
            "        [0.0000, 0.5956],\n",
            "        [0.0000, 0.0177],\n",
            "        [1.0000, 0.0464],\n",
            "        [0.0000, 0.0000]])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-c9b9ab514dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# output, mem_rec = net(X_batch.view(batch_size, -1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     Y_batch = Y_batch.contiguous().view(\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         -1)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[5, -1]' is invalid for input of size 6"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outer training loop\n",
        "for epoch in range(num_epochs):\n",
        "    iter_counter = 0\n",
        "    train_batch = iter(train_loader)\n",
        "\n",
        "    # Minibatch training loop\n",
        "    for data, targets in train_batch:\n",
        "        # print(data, targets)\n",
        "        # data = data[0]\n",
        "        targets = targets[0]\n",
        "\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # forward pass\n",
        "        net.train()\n",
        "        # spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
        "        spk_rec, mem_rec = net(data)\n",
        "        mem_rec = torch.swapaxes(mem_rec, 1, 2)\n",
        "        # print(mem_rec, targets)\n",
        "\n",
        "        # initialize the loss & sum over time\n",
        "        loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
        "\n",
        "        for step in range(num_steps):\n",
        "            loss_val += loss(mem_rec[step], targets)\n",
        "\n",
        "        print(loss_val)\n",
        "\n",
        "        # Gradient calculation + weight update\n",
        "        optimizer.zero_grad()\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store loss history for future plotting\n",
        "        loss_hist.append(loss_val.item())\n",
        "\n",
        "        # Test set\n",
        "        with torch.no_grad():\n",
        "            net.eval()\n",
        "            test_data, test_targets = next(iter(test_loader))\n",
        "\n",
        "            test_targets = test_targets[0]\n",
        "            # test_data = test_data[0]\n",
        "            test_data = test_data.to(device)\n",
        "            test_targets = test_targets.to(device)\n",
        "\n",
        "\n",
        "\n",
        "            # Test set forward pass\n",
        "            # test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
        "            test_spk, test_mem = net(test_data)\n",
        "            test_mem = torch.swapaxes(test_mem, 2, 1)\n",
        "\n",
        "            # Test set loss\n",
        "            test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
        "            for step in range(num_steps):\n",
        "                test_loss += loss(test_mem[step], test_targets)\n",
        "            test_loss_hist.append(test_loss.item())\n",
        "            \n",
        "\n",
        "\n",
        "            # Print train/test loss/accuracy\n",
        "            if counter % 50 == 0:\n",
        "                test_targets = torch.swapaxes(test_targets, 1, 0)\n",
        "                train_printer(\n",
        "                    data, targets, epoch,\n",
        "                    counter, iter_counter,\n",
        "                    loss_hist, test_loss_hist,\n",
        "                    test_data, test_targets)\n",
        "            counter += 1\n",
        "            iter_counter +=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "Pb-MEiXoaSzd",
        "outputId": "1628f9f1-705b-43a6-d5fe-d56d92ae4e72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-f0d0c6372636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# spk_rec, mem_rec = net(data.view(batch_size, -1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mspk_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mmem_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem_rec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print(mem_rec, targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-15c439f0f9a2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mspk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslstm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mspk2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslstm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/snntorch/_neurons/slstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_quant\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/snntorch/_neurons/slstm.py\u001b[0m in \u001b[0;36m_build_state_function\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m    225\u001b[0m             )\n\u001b[1;32m    226\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_mechanism_val\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# no reset, pure integration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mstate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_state_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstate_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/snntorch/_neurons/slstm.py\u001b[0m in \u001b[0;36m_base_state_function\u001b[0;34m(self, input_, syn, mem)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_base_state_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mbase_fn_mem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_fn_syn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbase_fn_syn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_fn_mem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         ret = _VF.lstm_cell(\n\u001b[0m\u001b[1;32m   1195\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_ih\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_hh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input has inconsistent input_size: got 12 expected 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Loss\n",
        "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
        "plt.plot(loss_hist)\n",
        "plt.plot(test_loss_hist)\n",
        "plt.title(\"Loss Curves\")\n",
        "plt.legend([\"Train Loss\", \"Test Loss\"])\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "j8gnsEy8wMVk",
        "outputId": "5c4f3c3e-0f2d-4e0c-fd31-499d55cfd530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brLeoA0owPg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}